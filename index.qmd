---
title: "Improved 21st Century Projections"
subtitle: "PhD Midterm Presentation"
author:
  - name: Brynjólfur Gauti Guðrúnar Jónsson
institute: "University of Iceland"
format: 
  revealjs:
    theme: theme.scss
    simplemenu:
      flat: false
      barhtml:
        header: "<div class='menubar mb-10'><ul class='menu'></ul><div>"
        footer: "<div class='footer footer-default' style='display: block;'> <a href='https://bggj.is/midtermpresentation' target='_blank'>bggj.is/midtermpresentation</a></div>"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
revealjs-plugins:
  - simplemenu
bibliography: references.bib
csl: cambridge-university-press-numeric.csl
---

## Extreme Precipitation {data-name="Background"}

::: {.columns}
::: {.column width="40%"}
![Reykjavík, 2016 [@mblreykjavik]](images/flod1.jpg){width="100%" fig-align="left" style="font-size:40%"}

![Siglufjörður, 2024 [@ruvsiglufjordur]](images/flod2.webp){width="100%" fig-align="left" style="font-size:40%"}
:::

::: {.column width="60%" style="font-size: 60%"}
- **Climate Change Impact**
  - Increasing frequency of extreme events
  - Higher intensity precipitation
  - Sub-daily timescale impacts

- **Modeling Challenges**
  - Complex spatial dependencies
  - High-resolution requirements
  - Non-stationary patterns

- **Research Goals**
  - Efficient statistical methods
  - Improved uncertainty quantification
  - Scalable computational approach
:::
:::

## Large Datasets

::: {.columns style="font-size:70%"}
::: {.column width="70%"}
-   UKCP Local Projections on a 5km grid over the UK (1980-2080) [@metoffi]
-   Challenge: Modeling maximum daily precipitation in yearly blocks
    -   43,920 spatial locations on a 180 x 244 grid
    -   Four parameters per location as in [@johannesson2021]
        -   Location, Trend, Scale, Shape
-   Two aspects of spatial dependence:
    1.  GEV parameters (Spatial models)
    2.  Data-level dependence (Copulas)
:::

::: {.column width="30%"}
![](images/ukcp_data.png){width="100%"}
:::
:::

## Max-and-Smooth

::: {.columns style="font-size:60%"}
### Two-Step Approach
::: {.column width="50%"}

1. **Max Step**: Maximum Likelihood
   - Independent local estimates $\hat{\eta}_i$
   - Asymptotic normality:
$$
\hat{\eta}_i \stackrel{a}{\sim} N(\eta_i, \mathbf{Q}_{\eta y,i}^{-1})
$$
   - Observed information matrix $\mathbf{Q}_{\eta y,i} = -\nabla^2\ell_i(\hat{\eta}_i)$

:::
::: {.column width="50%"}

2. **Smooth Step**: Spatial Model
   - Gaussian approximation:
$$
\hat{\eta} \mid \eta \sim N(\eta, \mathbf{Q}_{\eta y}^{-1})
$$
   - Latent field prior:
$$
\eta \mid \theta \sim N(0, \mathbf{Q}_\eta(\theta)^{-1})
$$
   - Hyperprior: $p(\theta)$
:::
:::

::: {style="font-size:65%; margin-top:20px;"}
**Posterior**: The joint posterior distribution becomes:

$$
p(\eta, \theta \mid \hat{\eta}) \propto p(\hat{\eta} \mid \eta)p(\eta \mid \theta)p(\theta)
$$

where $\eta$ is the latent field, $\theta$ are hyperparameters, and $\hat{\eta}$ are the local MLEs.
:::

## Calculating Multivariate Normal Densities

::: {.columns style="font-size:60%"}
$$
\log f(\mathbf{x}) \propto \frac{1}{2}\left(\log |\mathbf{Q}| - \mathbf{x}^T\mathbf{Q}\mathbf{x}\right)
$$

::: {.column width="50%"}
### Computational challenges

1.  **Log Determinant**: $\log |\mathbf{Q}|$
    -   Constant for a given precision matrix
2.  **Quadratic Form**: $\mathbf{x}^T\mathbf{Q}\mathbf{x}$
    -   Needs calculation for each density evaluation
:::

::: {.column width="50%"}
### Spatial Model Considerations

-   Some models (e.g., ICAR) avoid log determinant calculation
-   Efficient computation crucial for large-scale applications
-   Fast algorithms when $\mathbf{Q}$ is sparse [@rue2001; @rue2005]
:::
:::

## Spatial Models

::: {style="font-size:50%"}
#### Conditional Autoregression (CAR) [@besag1974]

::: columns
::: {.column width="50%"}
-   $\mathbf{D}$ is a diagonal matrix with $D_{ii} = n_i$, the number of neighbours of $i$
-   $\mathbf{A}$ is the adjacency matrix with $A_{ij} = A_{ji} = 1$ if $i \sim j$
:::

::: {.column width="50%"}
$$
\begin{aligned}
\mathbf{x} &\sim N(\mathbf{0}, \tau \mathbf{Q}) \\
\mathbf{Q} &= \mathbf{D}\left(\mathbf{I} - \alpha \mathbf{A} \right)
\end{aligned}
$$
:::
:::

------------------------------------------------------------------------

#### Intrinsic Conditional Autoregression (ICAR) [@besag1991]

::: columns
::: {.column width="50%"}
-   $\alpha = 1$, so $\mathbf Q$ is singular, but constant
-   Don't have to calculate $\log |\mathbf{Q}|$
:::

::: {.column width="50%"}
$$
\begin{aligned}
\mathbf{x} &\sim N(\mathbf{0}, \tau \mathbf{Q}) \\
\mathbf{Q} &= \mathbf{D} - \mathbf{A}
\end{aligned}
$$
:::
:::

------------------------------------------------------------------------

::: columns
::: {.column width="50%"}
#### BYM (Besag-York-Mollié) Model [@besag1991]

-   $\mathbf{u}$ is the structured spatial component (Besag model)
-   $\mathbf{v}$ is the unstructured component (i.i.d. normal)
:::

::: {.column width="50%"}
$$
\begin{aligned}
\mathbf{x} &= \mathbf{u} + \mathbf{v} \\
\mathbf{u} &\sim \mathrm{ICAR}(\tau_u) \\
\mathbf{v} &\sim N(\mathbf{0}, \tau_v^{-1})
\end{aligned}
$$
:::
:::

------------------------------------------------------------------------

::: columns
::: {.column width="50%"}
#### BYM2 Model [@riebler2016; @simpson2015]

-   $\rho$ models how much of variance is spatial
-   $s$ is a scaling factor chosen to make $\mathrm{Var}(\mathbf u_i) \approx 1$
:::

::: {.column width="50%"}
$$
\begin{aligned}
\mathbf{x} &= \left(\left(\sqrt{\rho/s}\right)\mathbf{u} + \left(\sqrt{1 - \rho}\right) \mathbf{v} \right)\sigma \\
\mathbf{u} &\sim \mathrm{ICAR}(1) \\
\mathbf{v} &\sim N(\mathbf{0}, n)
\end{aligned}
$$
:::
:::
:::

## From Parameter-level to Data-level Dependence

::: {.columns style="font-size:60%"}
::: {.column width="50%"}
### Parameter-level Dependence

-   Assumes conditional independence
-   Biased joint probability estimates
-   Underestimates parameter variance
:::

::: {.column width="50%"}
### Copula

-   Improves joint probabilities
-   Enhances spatial risk assessment
-   Better variance estimates
:::
:::

::: {style="font-size:65%; margin-top:20px;"}
**Sklar's Theorem**: For any multivariate distribution $H$, there exists a unique copula $C$ such that:

$$
H(\mathbf x) = C(F_1(x_1), \dots, F_d(x_d))
$$

where $F_i$ are marginal distributions. We can also write this as a density

$$
h(x) = c(F_1(x_1), \dots, F_d(x_d)) \prod_{i=1}^d f_i(x_i)
$$

:::

## Matérn-like Gaussian Copula {data-name="Copula"}

::: {style="font-size:55%"}

$$
\begin{gathered}
\log h(\mathbf x) = \log c\left(F_1(x_1), \dots, F_d(x_d)\right) + \sum_{i=1}^d \log f_i(x_i)
\end{gathered}
$$

------------------------------------------------------------------------

::: columns
### Marginal CDFs

::: {.column width="50%"}
-   $F_i(x_i)$ is $\mathrm{GEV}(\mu_i, \sigma_i, \xi_i)$
-   Can model parameter dependence with BYM2
:::

::: {.column width="50%"}
$$
\begin{aligned}
\log h(\mathbf x) &= \log c(u_1, \dots, u_d) \\
&+ \sum_{i=1}^d \log f_{\mathrm{GEV}}(x_i \vert \mu_i, \sigma_i, \xi_i) \\
u_i &= F_{\mathrm{GEV}}(x_i \vert \mu_i, \sigma_i, \xi_i)
\end{aligned}
$$
:::
:::

------------------------------------------------------------------------

::: columns
### Gaussian Copula

::: {.column width="50%"}
-   Matérn-like precision matrix $\mathbf{Q}$ [@lindgren2011]
-   If $\mathbf{Q} = \mathbf{I}$ simplifies to independent margins
-   Scaled so $\boldsymbol{\Sigma} = \mathbf{Q}^{-1}$ is correlation matrix
-   Need to calculate marginal variances [@rue2005a; @rue2007; @rue2009]
-   How to generate, scale and compute with $\mathbf{Q}$ quickly (for MCMC)?
:::

::: {.column width="50%"}
$$
\begin{aligned}
\log c(\mathbf u) &\propto \frac{1}{2}\left(\log |\mathbf{Q}| - \mathbf{z}^T\mathbf{Q}\mathbf{z} + \mathbf{z}^T\mathbf{z}\right) \\
\mathbf{z} &= \Phi^{-1}(\mathbf u)
\end{aligned}
$$
:::
:::
:::

## The Precision Matrix

::: {style="font-size:60%"}
$\mathbf Q$ defined as Kronecker sum of two AR(1) precision matrices, similar to [@lindgren2011]

$$
\mathbf{Q} = \left( \mathbf{Q}_{\rho_1} \otimes \mathbf{I_{n_2}} + \mathbf{I_{n_1}} \otimes \mathbf{Q}_{\rho_2} \right)^{\nu + 1}, \quad \nu \in \{0, 1, 2\}
$$

::: {.columns style="font-size:80%"}
::: {.column width="50%"}
$$
\mathbf{Q}_{\rho_{1}} = \frac{1}{1-\rho_{1}^2}
\begin{bmatrix}
1 & -\rho_{1} & 0 & \cdots & 0 \\
-\rho_{1} & 1+\rho_{1}^2 & -\rho_{1} & \cdots & 0 \\
0 & -\rho_{1} & 1+\rho_{1}^2 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{bmatrix}
$$
:::

::: {.column width="50%"}
$$
\mathbf{Q}_{\rho_{2}} = \frac{1}{1-\rho_{2}^2}
\begin{bmatrix}
1 & -\rho_{2} & 0 & \cdots & 0 \\
-\rho_{2} & 1+\rho_{2}^2 & -\rho_{2} & \cdots & 0 \\
0 & -\rho_{2} & 1+\rho_{2}^2 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{bmatrix}
$$
:::

$$
\mathbf Q = \begin{bmatrix}
\frac{1}{(1-\rho_1^2)}\mathbf{I_{n_2}} + \mathbf{Q_{\rho_2}} & \frac{-\rho_1}{(1-\rho_1^2)}\mathbf{I_{n_2}} & \dots & \cdots & \dots \\
\frac{-\rho_1}{(1-\rho_1^2)}\mathbf{I_{n_2}} & \frac{(1+\rho_1^2)}{(1-\rho_1^2)}\mathbf{I_{n_2}} + \mathbf{Q_{\rho_2}} & \frac{-\rho_1}{(1-\rho_1^2)} \mathbf{I_{n_2}} & \cdots & \vdots  \\
\vdots & \ddots & \ddots & \ddots & \vdots \\
\dots & \dots & \cdots & \frac{-\rho_1}{(1-\rho_1^2)} \mathbf{I_{n_2}} & \frac{1}{(1-\rho_1^2)}\mathbf{I_{n_2}} + \mathbf{Q_{\rho_2}}
\end{bmatrix}^{\nu + 1}
$$
:::
:::

## Eigendecomposition

::: {.columns style="font-size:65%"}
Because of how $\mathbf{Q}$ is defined [@horn1991], we know that

$$
\begin{aligned}
\mathbf{Q} &= \mathbf{V}\boldsymbol{\Lambda}\mathbf{V} \\
&= (\mathbf{V_{\rho_1}} \otimes \mathbf{V_{\rho_2}})(\boldsymbol \Lambda_{\rho_1} \otimes \mathbf{I} + \mathbf{I} \otimes \boldsymbol \Lambda_{\rho_2})^{\nu + 1}(\mathbf{V_{\rho_1}} \otimes \mathbf{V_{\rho_2}})^T
\end{aligned}
$$

where

$$
\begin{aligned}
\mathbf{Q}_{\rho_1} = \mathbf{V_{\rho_1}}\boldsymbol \Lambda_{\rho_1}\mathbf{V_{\rho_1}}^T \qquad \& \qquad
\mathbf{Q}_{\rho_2} = \mathbf{V_{\rho_2}}\boldsymbol \Lambda_{\rho_2}\mathbf{V_{\rho_2}}^T
\end{aligned}
$$

Spectral decomposition defined by value/vector pairs of smaller matrices

::: {.column width="50%"}
$$
\left\{\lambda_{\rho_1}\right\}_i + \left\{\lambda_{\rho_2}\right\}_j
$$
:::

::: {.column widht="50%"}
$$
\left\{\mathbf{v}_{\rho_1}\right\}_i \otimes \left\{\mathbf{v}_{\rho_2}\right\}_j
$$
:::

-   Problem: $\boldsymbol \Sigma_{ii} = \left(\mathbf Q^{-1} \right)_{ii} \neq  1$
-   Solution: $\mathbf{\widetilde  Q} = \mathbf{D}\mathbf{Q}\mathbf{D}$, where $\mathbf D_{ii} = \sqrt{\boldsymbol \Sigma_{ii}}$
:::

## Marginal Standard Deviations

::: {style="font-size:70%"}
$$
\boldsymbol \Sigma = \mathbf Q^{-1} = (\mathbf{V}\boldsymbol\Lambda\mathbf{V}^T)^{-1} = \mathbf{V}\boldsymbol \Lambda^{-1}\mathbf{V}
$$

We know that if $A = BC$ then $A_{ii} = B_{i, .} C_{., i}$, so

$$
\boldsymbol \Sigma_{ii} = \sum_{k=1}^{n} v_{ik} \frac{1}{\lambda_k} (v^T)_{ki} = \sum_{k=1}^{n} v_{ik} \frac{1}{\lambda_k} v_{ik} = \sum_{k=1}^{n} v_{ik}^2 \frac{1}{\lambda_k}
$$

Compute vector $\boldsymbol \sigma^2$ containing all marginal variances

$$ 
\boldsymbol \sigma^2 = \sum_{i = 1}^{n_1} \sum_{j=1}^{n_2} \frac{\left(\left\{\mathbf{v}_{\rho_1}\right\}_i \otimes \left\{\mathbf{v}_{\rho_2}\right\}_j\right)^{2}}{\quad\left(\left\{\lambda_{\rho_1}\right\}_i + \left\{\lambda_{\rho_2}\right\}_j\right)^{\nu+1}}
$$
:::

## Max-step: IID Case {data-name="Max-and-Smooth"}

::: {style="font-size:65%;"}
* $P$: number of stations, $N$: replicates at each station

**Independent Likelihood**: Marginal GEV distributions:

$$
\ell(\theta|Y) = \sum_{i=1}^P \ell_{\text{GEV}}(Y_{i}|\mu_i,\sigma_i,\xi_i) =
\sum_{i=1}^P \sum_{j=1}^N \ell_{\text{GEV}}(Y_{ij}|\mu_i,\sigma_i,\xi_i)
$$

**Multivariate Link Function**:
$$
\mu = e^\psi, \quad \sigma = e^{\psi + \tau}, \quad \xi = g(\phi)
$$

**Key Properties**:

- $\mathbf Q_{\eta y}$ is a banded matrix
- Parallel processing using L-BFGS with automatic differentiation
- Weak normal priors on transformed parameters

:::

## Max-step: Adding Dependence

::: {style="font-size:65%;"}
**Combined Likelihood**: Added Matérn-like Gaussian copula:

$$
\begin{gathered}
\ell(\theta|Y) = \sum_{j=1}^N \left[\sum_{i=1}^P \ell_{\text{GEV}}(Y_{ij}|\mu_i,\sigma_i,\xi_i) + \frac{1}{2}\left(\log|\mathbf{Q}| - Z_j^T\mathbf{Q}Z_j + Z_j^TZ_j\right) \right], \\
Z_j = \Phi^{-1}(U_j), \qquad
U_{ij} = F_\mathrm{GEV}(Y_{ij} \vert \mu_i, \sigma_i, \xi_i)
\end{gathered}
$$

**Key Changes**:

- $\mathbf Q_{\eta y}$ structure based on $\nu$, smoothness in the copula
- Parallel processing of replicates instead of stations
- $\mathbf Q$ assumed known
- Copula likelihood calculated using sparse representation of $L$
- Acklam's Algorithm for $\Phi^{-1}$ [@AcklamInvNorm]

:::

## Smooth-step

::: {style="font-size:65%;"}

**Gaussian Approximation**: Based on sparse Cholesky factor, $L$, of $Q_{\eta y}$

$$
\log p(\hat\eta \mid \eta, L) = \frac{1}{2}\log|Q_{\eta y}| - \frac{1}{2}\left\|\left(\sum_{j=1}^{n_i} L_{ij}(\hat\eta_{k_{ij}} - \eta_{k_{ij}})\right)_{i=1}^n\right\|^2
$$

**Spatial Prior**: BYM2 [@riebler2016; @simpson2015] model for each GEV parameter $k$

$$
\eta_k = \mu_k\mathbf{1} + \sigma_k(\sqrt{\rho_k/c} \cdot \eta^{\mathrm{spatial}}_k + \sqrt{1-\rho_k}\cdot\eta^{\mathrm{random}}_k),
$$

where $c$ is a scaling factor chosen so $E_{\mathrm{geo}}\left[\mathrm{Var}(\eta^{\text{spatial}}_k)\right] = 1$

**Prior Specifications**:

::: columns
::: {.column width="60%"}
- $\eta^{\text{spatial}}_k \sim \text{ICAR}$ [@besag1991] with sum-to-zero constraint
- $\eta^{\text{random}}_k \sim N(0,1)$
:::
::: {.column width="40%"}
- $\sigma_k \sim \text{Exp}(1)$
- $\rho_k \sim \text{Beta}(1,1)$
:::
:::


:::

## Gaussian Copula {data-name="Results"}

```{r}
library(gt)
library(readr)
read_csv(here::here("data", "benchmark_matern_likelihood.csv")) |> 
  gt() |> 
  cols_label(
    `Cholesky (Unscaled)` = "Cholesky",
    `Eigen (Unscaled)` = "Time",
    eig = "Eigen",
    sp_3 = "Relative",
    circ = "Time",
    sp_1 = "Relative",
    fol = "Time",
    sp_2 = "Relative"
  ) |> 
  tab_spanner(
    label = "Circulant",
    columns = 6:7
  ) |> 
  tab_spanner(
    label = "Folded",
    columns = 8:9
  ) |> 
  tab_spanner(
    label = "Eigen",
    columns = 3:4
  ) |> 
  tab_spanner(
    label = "Unscaled",
    2:4
  ) |> 
  tab_spanner(
    label = "Scaled",
    columns = 5:9
  ) |> 
  tab_caption(
    md("Benchmarking how long it takes to evaluate the density of a Mátern(&#x3BD;)-like field with correlation parameter &#x3C1;, either unscaled or scaled to have unit marginal variance")
  )  |> 
  opt_row_striping(TRUE)

```

## Max-and-Smooth

**Some results here (maybe about running time)**

## Paper 1 {data-name="Future Work"}

::: {.columns style="font-size:60%"}
::: {.column width="50%"}
### Theoretical Development

- Novel Matérn-like copula integration
- Efficient computational methods:
  - Kronecker sum decomposition
  - Eigendecomposition techniques
  - Folded circulant approximations
:::

::: {.column width="50%"}
### Key Contributions

- Mathematical framework for spatial extremes
- Computational efficiency for large grids
- Theoretical validation through simulation
- Improved spatial dependence modeling
:::
:::

## Paper 2

::: {.columns style="font-size:60%; margin-bottom:0px; padding-bottom:0px;"}
::: {.column width="50%"}
### UKCP Local Projections

- Analysis of 5km grid projections
- Sub-daily precipitation patterns
- Comparison with observed data
- Systematic bias identification
:::

::: {.column width="50%"}
### Methodology

- Hierarchical statistical modeling
- Spatial dependence calibration
- Uncertainty quantification
- Improved 21st century projections
:::
:::

::: {style="margin-top:-60px;padding-top:0px"}
```{dot}
//| label: paper2
//| file: paper2.dot
```
:::

## Paper 3

::: {.columns style="font-size:60%"}
::: {.column width="50%"}
### R Package Implementation

- Comprehensive software package
- C++ integration for efficiency
- Parallel processing capabilities
- User-friendly interface design
:::

::: {.column width="50%"}
### Features

- Documentation and vignettes
- Example datasets
- Visualization tools
- Integration with spatial packages
:::
:::

# References

::: {#refs style="font-size:55%"}
:::
